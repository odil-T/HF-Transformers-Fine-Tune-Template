{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bd65d58-73bd-4ad3-ae15-dec65bd90bc7",
   "metadata": {},
   "source": [
    "I will assume that you will run this notebook using Google Colab since they provide TPUs.\n",
    "\n",
    "Please check the length of the longest sequence in your dataset (longest input_ids).\n",
    "Then update the `max_length` argument of AutoTokenizer to match that length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28afe6fb-5ab9-4fcf-bb2e-8ba7f1c79af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6357004-a9cb-4eae-9f55-e42944218127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_scheduler\n",
    "from safetensors.torch import save_model\n",
    "from accelerate import Accelerator, notebook_launcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6885814d-4025-4a0d-a38f-de5e8d38841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    MODELS_SAVE_FOLDER = \"models\"\n",
    "    CHECKPOINT = \"bert-base-uncased\"\n",
    "    \n",
    "    NUM_EPOCHS = 3\n",
    "    BATCH_SIZE = 8\n",
    "    AGG_EVERY_N_BATCHES = 100\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)\n",
    "    raw_datasets = datasets.load_dataset(\"glue\", \"mrpc\")\n",
    "    \n",
    "    \n",
    "    def preprocess(sample):\n",
    "        return tokenizer(sample[\"sentence1\"], sample[\"sentence2\"], truncation=True, padding=\"max_length\", max_length=104, return_tensors=\"pt\")\n",
    "    \n",
    "    \n",
    "    tokenized_datasets = raw_datasets.map(preprocess, batched=True)\n",
    "    tokenized_datasets = tokenized_datasets.remove_columns([\"sentence1\", \"sentence2\", \"idx\"])\n",
    "    tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "    \n",
    "    train_dataloader = DataLoader(tokenized_datasets[\"train\"], batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_dataloader = DataLoader(tokenized_datasets[\"validation\"], batch_size=BATCH_SIZE)\n",
    "    test_dataloader = DataLoader(tokenized_datasets[\"test\"], batch_size=BATCH_SIZE)\n",
    "    \n",
    "    NUM_TRAINING_STEPS = NUM_EPOCHS * len(train_dataloader)\n",
    "    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(CHECKPOINT)\n",
    "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "    lr_scheduler = get_scheduler(\n",
    "        \"linear\",\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=NUM_TRAINING_STEPS\n",
    "    )\n",
    "    \n",
    "    accelerator = Accelerator()\n",
    "    train_dataloader, val_dataloader, model, optimizer = accelerator.prepare(\n",
    "        train_dataloader, val_dataloader, model, optimizer\n",
    "    )\n",
    "    \n",
    "    \n",
    "    def train_loop():\n",
    "        \"\"\"\n",
    "        We usually calculate the mean training loss and some metric (e.g. accuracy) for every N number of batches.\n",
    "        \"\"\"\n",
    "    \n",
    "        model.train()\n",
    "        progress_bar = tqdm(total=len(train_dataloader))\n",
    "    \n",
    "        running_loss = 0.\n",
    "        running_n_correct_predictions = 0\n",
    "    \n",
    "    \n",
    "        for i, batch in enumerate(train_dataloader, start=1):\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            outputs = model(**batch)\n",
    "    \n",
    "            loss = outputs.loss\n",
    "            running_loss += loss.item()\n",
    "    \n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            running_n_correct_predictions += (predictions == batch[\"labels\"]).type(torch.int).sum().item()\n",
    "    \n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "    \n",
    "            progress_bar.update(1)\n",
    "    \n",
    "            if not i % AGG_EVERY_N_BATCHES:\n",
    "                avg_loss = running_loss / AGG_EVERY_N_BATCHES\n",
    "                running_loss = 0.\n",
    "    \n",
    "                accuracy = (running_n_correct_predictions / (AGG_EVERY_N_BATCHES * BATCH_SIZE)) * 100\n",
    "                running_n_correct_predictions = 0\n",
    "    \n",
    "                print(f\"Batch {i} | Training Loss: {avg_loss} | Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "        # Necessary to calculate average loss for any remainder batches (e.g. 63 batches left from 1463 when SHOW_EVERY_N_BATCHES = 100)\n",
    "        remaining_n_batches = (len(train_dataloader) % AGG_EVERY_N_BATCHES)\n",
    "        avg_loss = running_loss / remaining_n_batches\n",
    "        accuracy = (running_n_correct_predictions / (remaining_n_batches * BATCH_SIZE)) * 100\n",
    "    \n",
    "        return avg_loss, accuracy\n",
    "    \n",
    "    \n",
    "    def val_loop():\n",
    "        \"\"\"\n",
    "        We only calculate the mean validation loss and some metric (e.g. accuracy) over the whole epoch for the validation set.\n",
    "        No mean calculations are made for every N number of batches.\n",
    "        \"\"\"\n",
    "    \n",
    "        model.eval()\n",
    "        running_loss = 0.\n",
    "        running_n_correct_predictions = 0\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_dataloader):\n",
    "                outputs = model(**batch)\n",
    "    \n",
    "                loss = outputs.loss\n",
    "                running_loss += loss.item()\n",
    "    \n",
    "                logits = outputs.logits\n",
    "                predictions = torch.argmax(logits, dim=-1)\n",
    "                running_n_correct_predictions += (predictions == batch[\"labels\"]).type(torch.int).sum().item()\n",
    "    \n",
    "    \n",
    "        avg_loss = running_loss / len(val_dataloader)\n",
    "        accuracy = (running_n_correct_predictions / (len(val_dataloader) * BATCH_SIZE)) * 100\n",
    "    \n",
    "        return avg_loss, accuracy\n",
    "    \n",
    "    \n",
    "    def test_loop():\n",
    "        \"\"\"\n",
    "        We only calculate the mean test loss and some metric (e.g. accuracy) over one epoch for the test set.\n",
    "        \"\"\"\n",
    "    \n",
    "        model.eval()\n",
    "        running_loss = 0.\n",
    "        running_n_correct_predictions = 0\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_dataloader):\n",
    "                outputs = model(**batch)\n",
    "    \n",
    "                loss = outputs.loss\n",
    "                running_loss += loss.item()\n",
    "    \n",
    "                logits = outputs.logits\n",
    "                predictions = torch.argmax(logits, dim=-1)\n",
    "                running_n_correct_predictions += (predictions == batch[\"labels\"]).type(torch.int).sum().item()\n",
    "    \n",
    "    \n",
    "        avg_loss = running_loss / len(test_dataloader)\n",
    "        accuracy = (running_n_correct_predictions / (len(test_dataloader) * BATCH_SIZE)) * 100\n",
    "    \n",
    "        return avg_loss, accuracy\n",
    "    \n",
    "    \n",
    "    Path(MODELS_SAVE_FOLDER).mkdir(exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y_%m_%d__%H_%M_%S')\n",
    "    best_val_loss = 1_000_000.\n",
    "    \n",
    "    for epoch in range(1, NUM_EPOCHS+1):\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "    \n",
    "        avg_train_loss, train_accuracy = train_loop()\n",
    "        print(f\"Training Loss: {avg_train_loss} | Training Accuracy: {train_accuracy:.2f}%\")\n",
    "    \n",
    "        avg_val_loss, val_accuracy = val_loop()\n",
    "        print(f\"Validation Loss: {avg_val_loss} | Validation Accuracy: {val_accuracy:.2f}%\", end='\\n\\n')\n",
    "    \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            model_path = f\"{MODELS_SAVE_FOLDER}/model_bert_epoch{epoch}_{timestamp}\"\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "            # You may choose to save as safetensors\n",
    "            # save_model(model, f\"{model_path}.safetensors\")\n",
    "    \n",
    "    avg_test_loss, test_accuracy = test_loop()\n",
    "    print(f\"Test Loss: {avg_test_loss} | Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced8dc8d-9c50-424c-9129-32880dc1f26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_launcher(main)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
